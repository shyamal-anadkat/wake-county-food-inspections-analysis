{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a5755f1",
   "metadata": {},
   "source": [
    "## Wake County - Restaurant Food Inspections Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b0008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas, numpy, matplotlib, seaborn \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# importing the requests library\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129c629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39911d9e",
   "metadata": {},
   "source": [
    "### Resources\n",
    " 1. [Restaurants in Wake County Data Info](https://www.arcgis.com/home/item.html?id=124c2187da8c41c59bde04fa67eb2872)\n",
    " 2. [Wake County Open Data](https://data-wake.opendata.arcgis.com/search?tags=restaurants)\n",
    " 3. [Food Inspection Violations Data Info](https://data.wakegov.com/datasets/Wake::food-inspection-violations/about)\n",
    " 4. [Wake County Yelp Initiative](https://ash.harvard.edu/news/wake-county-yelp-initiative)\n",
    " 5. [Yelp LIVES data](https://www.yelp.com/healthscores/feeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6d510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ipynb if this fails\n",
    "# the first time you run this, it will execute these, but run it again if you'd like\n",
    "# warning: there's an issue where the arguments won't work so just use no-arg functions to pull\n",
    "from ipynb.fs.full.RestaurantInspectionsData import getFoodInspectionsDf, preprocess_inspections\n",
    "from ipynb.fs.full.RestaurantsData import getRestaurantsDf, preprocess_restaurants\n",
    "from ipynb.fs.full.RestaurantViolationsData import getViolationsDf, preprocess_violations\n",
    "from ipynb.fs.full.WeatherData import getWeatherData, preprocess_weatherdata\n",
    "from ipynb.fs.full.YelpReviewData import preprocess_restaurants_yelp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6765dce",
   "metadata": {},
   "source": [
    "## Fetch Inspections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2494e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_inspections_raw = getFoodInspectionsDf()\n",
    "inspections = preprocess_inspections(food_inspections_raw.copy())\n",
    "inspections.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2c28cc",
   "metadata": {},
   "source": [
    "## Fetch Restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85823c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants_raw = getRestaurantsDf()\n",
    "restaurants = preprocess_restaurants(restaurants_raw.copy())\n",
    "restaurants.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a3462",
   "metadata": {},
   "source": [
    "## Fetch violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da125f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "violations_raw = getViolationsDf()\n",
    "violations = preprocess_violations(violations_raw.copy())\n",
    "violations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281205d1",
   "metadata": {},
   "source": [
    "## Fetch weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002ee9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherdata_raw = getWeatherData()\n",
    "weatherdata = preprocess_weatherdata(weatherdata_raw.copy())\n",
    "weatherdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc09d71",
   "metadata": {},
   "source": [
    "## Fetch Yelp Ratings Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8f6cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of restaurants with all relevant information plus phone number post-preprocessing\n",
    "restaurants_yelp_raw = getRestaurantsDf()\n",
    "restaurants_yelp = preprocess_restaurants_yelp(restaurants_yelp_raw.copy())\n",
    "restaurants_yelp.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3bc90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to csv\n",
    "restaurants_yelp.to_csv('restaurants_yelp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6943738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in processed yelp data\n",
    "yelpmatch_phone = pd.read_csv('yelpmatch_phone.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d7cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelpmatch_phone.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83f9204",
   "metadata": {},
   "source": [
    "## Fetch monthly/daily crime proxy data (Hearsch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78f40bd",
   "metadata": {},
   "source": [
    "## Next Steps ( we have T-minus 2 weeks!!!! !!!!!! FREAK OUTTTTT !!!!) \n",
    "0. Pull the police incidents/crime data and possibly cencus tracked income by location - Hearsch & Shyamal \n",
    "1. Make sure yelp data is sourced in this main notebook (minimal datapoints: ratings, dollar signs, type/cuisine, review metadata, other features at Ms. Park's discretion)\n",
    "2. Clean & Validate the data as part of Data Prep, EDA. Join tables by inspection. We want historical data per inspection and then we want to predict the risk scores for restaurants in high risk for future inspections. Note that although we have data around inspections by date, we don't really want to do a time series forecasting,bc time series forecasting sucks!\n",
    "3. Deal with missing values and encode variables \n",
    "4. Feature engineering \n",
    "5. Baseline model\n",
    "6. More complicated model\n",
    "7. Datasheets for datasets (ask Jon about this in next class if we need datasheet for every table or for every source) - Christine \n",
    "8. Hearsch - Ethical checklist \n",
    "9. Visualizations and story telling!\n",
    "10. Get started on a slideshow (FUN PART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5b1904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
